---
title: "Homework 3 "
output: github_document
date: 10/16/2024 (Due date)
---

```{r setup, include = FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)
```

## Problem 1
```{r data import, include = FALSE}
library(p8105.datasets) 
data("ny_noaa") 

ny_noaa #view variable types

#Make sure to comment on structure of data
# variable units from https://p8105.com/dataset_noaa.html
```

**Dataset Description**

The `ny_noaa` dataset, which was uploaded from the _p8105.dataset_ package, contains `r ncol(ny_noaa)` variables and `r nrow(ny_noaa)` observations. Character variables include weather station ID (`id`), `tmax`, and `tmin`. Integer variables include `prcp`, `snow`, and `snwd`. There is also a `date` variable, which is entered in YYYY-MM-DD format. After viewing the variable types in the dataset, I converted `tmax` and `tmin` into doubles. Using `summary()`, we get the following information:

```{r convert variables, include = FALSE}
ny_noaa = ny_noaa |>
  mutate(
    tmax = as.double(tmax),
    tmin = as.double(tmin))

summary(ny_noaa)
```

* Precipitation (`prcp`) ranges from 0 to 22860 tenths of mm. The mean is 29.82 tenths of mm. 145838 entries have NA values for this variable.
* Snowfall (`snow`) ranges from -13 mm to 10160 mm. The mean is 5 mm. 381221 entries have NA values for this variable.
* Snow depth (`snwd`) ranges from 0 mm to 9195 mm. The mean is 37.3 mm. 591786 entries have NA values for this variable. 
* Maximum temperature (`tmax`) ranges from -389 to 600 tenths of degrees C with a mean of 139.8. 1132358 entries have  NA values for this variable.
* Mininun temperature (`tmin`) ranges from -594 to 600 tenths of degrees C with a mean of 30.3. 1134420 entries have  NA values for this variable.

As you can see by looking at the number of entries with NAs for each of the variables above, missing data is quite an issue in this dataset. 

#### Task 1

```{r split date, include =FALSE}
ny_noaa = ny_noaa |>
   separate(date, into = c("year", "month", "day"), sep = "-") |>
  mutate(
    tmax = tmax/10, #changed units of temperature to °C
    tmin = tmin/10, #changed units of temperature to °C
    prcp = prcp/10) #changed units of temperature to mm

```

In the dataset, I created 3 additional date variables by splitting `date` into `year`, `month`, and `day`.

To ensure observations for temperature, precipitation, and snowfall are given in reasonable units, I converted the values in `tmax` and `tmin` to have °C as the units (instead of tenths of °C). Similarly, the unit for precipitation (`prcp`) has been converted to just mm. Snowfall is in reasonable units (mm).

```{r snowcount, include = FALSE}
ny_noaa_sf = ny_noaa |>
  mutate(snow = as.factor(snow)) |>
  count(snow, sort = TRUE)

```

For snowfall (`snow`), the top 3 most commonly observed values are 0mm (77.39%, n=2008508), 25mm (1.20%, n=31022), and 13mm (0.89%, n=23095). It may be important to note that 14.69% of the observations had NAs (n=381221). 

The relatively high percentage of empty observations for snowfall is due to inconsistent data collection of each weather station. Some of these weather stations may collect a portion of the variables. In general, it makes sense that most of the observations recorded by the New York state weather stations had 0mm for snow since the data is collected from the time period between January 1, 1981 through December 31, 2010 and not just during winter months. 

#### Task 2 

```{r two-panel plot, echo = FALSE, message = FALSE, warning = FALSE}
Jan_july = ny_noaa |>
  filter(month == "01" | month == "07") |>
  mutate(month = case_match(
    month, 
    "07" ~ "July",
    "01" ~ "January"))

avg_tmax = Jan_july |> #calc avg tmax for each station by month and year
  group_by(id, month, year) |>
  summarize(avg_tmax = mean(tmax),.groups = 'drop')

ggplot(avg_tmax, aes(x = year, y = avg_tmax)) + 
  geom_point(aes(color = month), alpha = 0.5) +
  geom_smooth(se = FALSE) +
  scale_x_discrete(
    breaks = c("1981", "1991", "2001", "2010"), # make axis easier to read
    labels = c("1981", "1991", "2001", "2010")) + 
  facet_grid(. ~ month) +
  labs(title = "Avg Max Temp of Weater Stations from 1981 to 2010, January vs. July",
       x = "Year",
       y = "Avg Max Temp in Celsius") 
```

There seem to be a few outliers in the January and July plots. For example, in January 1982, there is a data point that is less than -10 degrees C. In January 2008, there is another outlier with an average max temp of < -5 degrees C. For the July plot, we see more outliers than in the January plot. In particular, in July of 1988, there is an outlier with an average max temperature that is less than 15 degrees C.  

```{r geom_hex, echo = FALSE, message = FALSE, warning = FALSE}
ggplot(avg_tmax, aes(x = year, y = avg_tmax)) +
  geom_hex() +
  scale_x_discrete(
    breaks = c("1981", "1991", "2001", "2010"), # make axis easier to read
    labels = c("1981", "1991", "2001", "2010")) + 
  facet_grid(. ~ month) +
  labs(title = "Avg Max Temp of Weater Stations from 1981 to 2010, January vs. July",
       x = "Year",
       y = "Avg Max Temp in Celsius") 
```
Using the function `geom_hex()`, we see that the average max temperature in July seems to be fairly consistent among the weather stations across the years from 1981 to 2010 with a few outliers. For the January plot, we see more variation.

#### Task 3

```{r fulldata plot, echo = FALSE, message = FALSE, warning = FALSE}
plot1 = ggplot(ny_noaa, aes(x = tmin, y = tmax)) +
  geom_hex() +
  labs(title = "Temperature Distribution",
       x = "Minimum Temperature (°C)",
       y = "Maximum Temperature (°C)")
```

```{r snowfall plot, echo = FALSE, message = FALSE, warning = FALSE}
snowf = ny_noaa |>
  mutate(snowfall = ifelse(snow > 0, "Greater than 0mm", "Less than 0mm")) 

plot2 = ggplot(snowf, aes(x = year, y = snow, fill = snowfall)) +
  geom_hex() +
  scale_x_discrete(
    breaks = c("1981", "1991", "2001", "2010"), # make axis easier to read
    labels = c("1981", "1991", "2001", "2010")) + 
  labs(title = "Snowfall Distribution",
       x = "Year",
       y = "Snowfall (mm)") 

#combine plots
plot1 + plot2

```
The plot on the left shows the distribution of minimum temperature and maximum temperature for the entire dataset. 

The plot on the right shows the distribution of snowfall in mm across the years from 1981 to 2010. Outliers can be seen for snowfall greater than 0mm.  

## Problem 2

#### Task 1
_"nhanes_covar.csv"_ has been uploaded as the `demo_df` dataset. Using `summary()`, we see that there are 4 NAs for BMI and 18 NAs for education. All 5 variables are numeric (`SEQN`, `sex`, `age`, `BMI` and `Education`. There are 250 unique SEQNs, one for each participant. 

```{r demo import, include = FALSE}
demo_df = read_csv("./data/Accelerometer/nhanes_covar.csv", na = c("NA", ".", ""), skip = 4)

summary(demo_df)
# 4 NA for BMI, 18 NA for education
# all variables are doubles
#250 observations/participants; 5 variables

#sex: 1 = male, 2 = female
#education: 1 = less than high school, 2 = high school equivalent, 3 = more than high school
```

_"nhanes_accel.csv"_ has been uploaded as the `accel_df` dataset. There are 250 SEQNs, which reflects those that are in the `demo_df` dataset. All 1441 variables are numeric (dbl). Measurements are collected for `min1` to `min1440`.

```{r accelerometer import, include = FALSE}
accel_df =
  read_csv("./data/Accelerometer/nhanes_accel.csv", na = c("NA", ".", "")) # 250 obs, 1441 var

accel_df # all variables are doubles
```

The two dataset are then merged into the `merged_df` dataset, which contains all orignially observed variables. Participants less than 21 years old and those with missing demographic data (those with NAs for BMI and education, as mentioned above) are excluded. `SEQN`, `sex`, and `education` are converted into factors in preparation for generating tables and plots.

```{r merged, include = FALSE}
merged_df = merge(demo_df, accel_df, by = "SEQN", all = TRUE) |>
  filter(age >= 21) |>
   drop_na("BMI", "education") |> #know for summary(demo_df) that there are NAs in these var
  mutate(
    SEQN = as.factor(SEQN),
    sex = as.factor(sex),
    education = as.factor(education),
    sex = case_match(sex, "1" ~ "Male", "2" ~ "Female"),
    education = case_match(education, "1" ~ "Less than high school", "2" ~ "High school equivalent", "3" ~ "More than high school"))
  
#228 participants left, 1445 variables
#Variables *MIMS are the MIMS values for each minute of a 24-hour day starting at midnight.
```

#### Task 2

**Number of Men vs. Women per Education Category**

```{r, echo = FALSE}
gender = merged_df |>
  mutate(Education = education) |>
  janitor::tabyl(Education, sex)

knitr::kable(gender)
```

* At the "High school equivalent" level, there are more males than females by 12 individuals.
* At the "Less than high school" level, the numbers are similar, with females higher by one individual.
* At the "More than high school" level, females are higher in number by 3 individuals.

**Age Distributions for Men vs. Women per Education Category**

```{r age distribution, echo = FALSE}
merged_df |>
  ggplot(aes(x = education, y = age, fill = sex)) + 
  geom_boxplot() +
    labs(title = "Male vs. Female Age Distribution by Education",
       x = "Education Level",
       y = "Age (yrs)") 
```

* At the "High school equivalent" level, females have a higher age average when compared to males.
* At the "Less than high school" level, the average age is similar between male and females, with females having a slightly higher average age.
* At the "More than high school" level, the average age is higher in males when compared to females. 

#### Task 3
Traditional analyses of accelerometer data focus on the total activity over the day. Using your tidied dataset, aggregate across minutes to create a total activity variable for each participant. Plot these total activities (y-axis) against age (x-axis); your plot should compare men to women and have separate panels for each education level. Include a trend line or a smooth to illustrate differences. Comment on your plot. 

#### Task 4
Accelerometer data allows the inspection activity over the course of the day. Make a three-panel plot that shows the 24-hour activity time courses for each education level and use color to indicate sex. Describe in words any patterns or conclusions you can make based on this graph; including smooth trends may help identify differences. 

## Problem 3

```{r CitiBike setup, include = FALSE}
Jan2020_df =
  read_csv("./data/CitiBike/Jan 2020 citi.csv", na = c("NA", ".", ""))

Jan2024_df =
  read_csv("./data/CitiBike/Jan 2024 citi.csv", na = c("NA", ".", ""))

July2020_df =
  read_csv("./data/CitiBike/July 2020 citi.csv", na = c("NA", ".", ""))

July2024_df =
  read_csv("./data/CitiBike/July 2024 citi.csv", na = c("NA", ".", ""))

# data on rides taken on the NYC Citi Bike system. Files contain 1% of all rides with a total duration less than 4 hours in each of four months.
```

#### Task 1

Import, clean, and tidy these data, and describe the resulting dataset. 

#### Task 2

Produce a reader-friendly table showing the total number of rides in each combination of year and month separating casual riders and Citi Bike members. Comment on these results. 

#### Task 3

Make a table showing the 5 most popular starting stations for July 2024; include the number of rides originating from these stations. 

#### Task 4
Make a plot to investigate the effects of day of the week, month, and year on median ride duration. This plot can include one or more panels, but should facilitate comparison across all variables of interest. Comment on your observations from this plot. 

#### Task 5

There were relatively few electric Citi Bikes in 2020, but many more are available now. For data in 2024, make a figure that shows the impact of month, membership status, and bike type on the distribution of ride duration. Comment on your results. 
