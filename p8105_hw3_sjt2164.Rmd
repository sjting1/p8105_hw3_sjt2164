---
title: "Homework 3 "
output: github_document
date: 10/16/2024 (Due date)
---

```{r library setup, include = FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)
```

## Problem 1
```{r data import, include = FALSE}
library(p8105.datasets) 
data("ny_noaa") 

ny_noaa #view variable types

#Make sure to comment on structure of data
# variable units from https://p8105.com/dataset_noaa.html
```

**Dataset Description**

The `ny_noaa` dataset, which was uploaded from the _p8105.dataset_ package, contains `r ncol(ny_noaa)` variables and `r nrow(ny_noaa)` observations. Character variables include weather station ID (`id`), `tmax`, and `tmin`. Integer variables include `prcp`, `snow`, and `snwd`. There is also a `date` variable, which is entered in YYYY-MM-DD format. After viewing the variable types in the dataset, I converted `tmax` and `tmin` into doubles. Using `summary()`, we get the following information:

```{r convert variables, include = FALSE}
ny_noaa = ny_noaa |>
  mutate(
    tmax = as.double(tmax),
    tmin = as.double(tmin))

summary(ny_noaa)
```

* Precipitation (`prcp`) ranges from 0 to 22860 tenths of mm. The mean is 29.82 tenths of mm. 145838 entries have NA values for this variable.
* Snowfall (`snow`) ranges from -13 mm to 10160 mm. The mean is 5 mm. 381221 entries have NA values for this variable.
* Snow depth (`snwd`) ranges from 0 mm to 9195 mm. The mean is 37.3 mm. 591786 entries have NA values for this variable. 
* Maximum temperature (`tmax`) ranges from -389 to 600 tenths of degrees C with a mean of 139.8. 1132358 entries have  NA values for this variable.
* Mininun temperature (`tmin`) ranges from -594 to 600 tenths of degrees C with a mean of 30.3. 1134420 entries have  NA values for this variable.

As you can see by looking at the number of entries with NAs for each of the variables above, missing data is quite an issue in this dataset. 

#### Task 1

```{r split date, include =FALSE}
ny_noaa = ny_noaa |>
   separate(date, into = c("year", "month", "day"), sep = "-") |>
  mutate(
    tmax = tmax/10, #changed units of temperature to °C
    tmin = tmin/10, #changed units of temperature to °C
    prcp = prcp/10) #changed units of temperature to mm

```

In the dataset, I created 3 additional date variables by splitting `date` into `year`, `month`, and `day`.

To ensure observations for temperature, precipitation, and snowfall are given in reasonable units, I converted the values in `tmax` and `tmin` to have °C as the units (instead of tenths of °C). Similarly, the unit for precipitation (`prcp`) has been converted to just mm. Snowfall is in reasonable units (mm).

```{r snowcount, include = FALSE}
ny_noaa_sf = ny_noaa |>
  mutate(snow = as.factor(snow)) |>
  count(snow, sort = TRUE)

```

For snowfall (`snow`), the top 3 most commonly observed values are 0mm (77.39%, n=2008508), 25mm (1.20%, n=31022), and 13mm (0.89%, n=23095). It may be important to note that 14.69% of the observations had NAs (n=381221). 

The relatively high percentage of empty observations for snowfall is due to inconsistent data collection of each weather station. Some of these weather stations may collect a portion of the variables. In general, it makes sense that most of the observations recorded by the New York state weather stations had 0mm for snow since the data is collected from the time period between January 1, 1981 through December 31, 2010 and not just during winter months. 

#### Task 2 

```{r two-panel plot, echo = FALSE, message = FALSE, warning = FALSE}
Jan_july = ny_noaa |>
  filter(month == "01" | month == "07") |>
  mutate(month = case_match(
    month, 
    "07" ~ "July",
    "01" ~ "January"))

avg_tmax = Jan_july |> #calc avg tmax for each station by month and year
  group_by(id, month, year) |>
  summarize(avg_tmax = mean(tmax),.groups = 'drop')

ggplot(avg_tmax, aes(x = year, y = avg_tmax)) + 
  geom_point(aes(color = month), alpha = 0.5) +
  geom_smooth(se = FALSE) +
  scale_x_discrete(
    breaks = c("1981", "1991", "2001", "2010"), # make axis easier to read
    labels = c("1981", "1991", "2001", "2010")) + 
  facet_grid(. ~ month) +
  labs(title = "Avg Max Temp of Weater Stations from 1981 to 2010, January vs. July",
       x = "Year",
       y = "Avg Max Temp in Celsius") 
```

There seem to be a few outliers in the January and July plots. For example, in January 1982, there is a data point that is less than -10 degrees C. In January 2008, there is another outlier with an average max temp of < -5 degrees C. For the July plot, we see more outliers than in the January plot. In particular, in July of 1988, there is an outlier with an average max temperature that is less than 15 degrees C.  

```{r geom_hex, echo = FALSE, message = FALSE, warning = FALSE}
ggplot(avg_tmax, aes(x = year, y = avg_tmax)) +
  geom_hex() +
  scale_x_discrete(
    breaks = c("1981", "1991", "2001", "2010"), # make axis easier to read
    labels = c("1981", "1991", "2001", "2010")) + 
  facet_grid(. ~ month) +
  labs(title = "Avg Max Temp of Weater Stations from 1981 to 2010, January vs. July",
       x = "Year",
       y = "Avg Max Temp in Celsius") 
```
Using the function `geom_hex()`, we see that the average max temperature in July seems to be fairly consistent among the weather stations across the years from 1981 to 2010 with a few outliers. For the January plot, we see more variation.

#### Task 3

```{r fulldata plot, echo = FALSE, message = FALSE, warning = FALSE}
plot1 = ggplot(ny_noaa, aes(x = tmin, y = tmax)) +
  geom_hex() +
  labs(title = "Temperature Distribution",
       x = "Minimum Temperature (°C)",
       y = "Maximum Temperature (°C)")
```

```{r snowfall plot, echo = FALSE, message = FALSE, warning = FALSE}
snowf = ny_noaa |>
  mutate(snowfall = ifelse(snow > 0, "Greater than 0mm", "Less than 0mm")) 

plot2 = ggplot(snowf, aes(x = year, y = snow, fill = snowfall)) +
  geom_hex() +
  scale_x_discrete(
    breaks = c("1981", "1991", "2001", "2010"), # make axis easier to read
    labels = c("1981", "1991", "2001", "2010")) + 
  labs(title = "Snowfall Distribution",
       x = "Year",
       y = "Snowfall (mm)") 

#combine plots
plot1 + plot2

```
The plot on the left shows the distribution of minimum temperature and maximum temperature for the entire dataset. 

The plot on the right shows the distribution of snowfall in mm across the years from 1981 to 2010. Outliers can be seen for snowfall greater than 0mm.  

## Problem 2

#### Task 1
_"nhanes_covar.csv"_ has been uploaded as the `demo_df` dataset. Using `summary()`, we see that there are 4 NAs for BMI and 18 NAs for education. All 5 variables are numeric (`SEQN`, `sex`, `age`, `BMI` and `Education`. There are 250 unique SEQNs, one for each participant. 

```{r demo import, include = FALSE}
demo_df = read_csv("./data/Accelerometer/nhanes_covar.csv", na = c("NA", ".", ""), skip = 4)

summary(demo_df)
# 4 NA for BMI, 18 NA for education
# all variables are doubles
#250 observations/participants; 5 variables

#sex: 1 = male, 2 = female
#education: 1 = less than high school, 2 = high school equivalent, 3 = more than high school
```

_"nhanes_accel.csv"_ has been uploaded as the `accel_df` dataset. There are 250 SEQNs, which reflects those that are in the `demo_df` dataset. All 1441 variables are numeric (dbl). Measurements are collected for `min1` to `min1440`.

```{r accelerometer import, include = FALSE}
accel_df =
  read_csv("./data/Accelerometer/nhanes_accel.csv", na = c("NA", ".", "")) # 250 obs, 1441 var

accel_df # all variables are doubles
```

The two dataset are then merged into the `merged_df` dataset, which contains all orignially observed variables. Participants less than 21 years old and those with missing demographic data (those with NAs for BMI and education, as mentioned above) are excluded. `SEQN`, `sex`, and `education` are converted into factors in preparation for generating tables and plots.

```{r merged, include = FALSE}
merged_df = merge(demo_df, accel_df, by = "SEQN", all = TRUE) |>
  filter(age >= 21) |>
   drop_na("BMI", "education") |> #know for summary(demo_df) that there are NAs in these var
  mutate(
    SEQN = as.factor(SEQN),
    sex = as.factor(sex),
    education = as.factor(education),
    sex = case_match(sex, "1" ~ "Male", "2" ~ "Female"),
    education = case_match(education, "1" ~ "Less than high school", "2" ~ "High school equivalent", "3" ~ "More than high school"))
  
#228 participants left, 1445 variables
#Variables *MIMS are the MIMS values for each minute of a 24-hour day starting at midnight.
```

#### Task 2

**Number of Men vs. Women per Education Category**

```{r, echo = FALSE}
gender = merged_df |>
  mutate(Education = education) |>
  janitor::tabyl(Education, sex)

knitr::kable(gender)
```

* At the "High school equivalent" level, there are more males than females by 12 individuals.
* At the "Less than high school" level, the numbers are similar, with females higher by one individual.
* At the "More than high school" level, females are higher in number by 3 individuals.

**Age Distributions for Men vs. Women per Education Category**

```{r age distribution, echo = FALSE}
merged_df |>
  ggplot(aes(x = education, y = age, fill = sex)) + 
  geom_boxplot() +
    labs(title = "Male vs. Female Age Distribution by Education",
       x = "Education Level",
       y = "Age (yrs)") 
```

* At the "High school equivalent" level, females have a higher age average when compared to males.
* At the "Less than high school" level, the average age is similar between male and females, with females having a slightly higher average age.
* At the "More than high school" level, the average age is higher in males when compared to females. 

#### Task 3

Since traditional analyses of accelerometer data focus on the total activity over the day, values in `min1` through `min1440` for each participant was summed into the variable `total_activity`. This was done by grouping `SEQN`, `sex`, `age`, `BMI`, and `education`.

```{r total activity, echo = FALSE, message = FALSE}
merged_df_updated = merged_df |>
    pivot_longer(
    cols = min1:min1440, 
    names_to = "min_number", 
    values_to = "value") 

merged_df_updated |>
    group_by(SEQN, sex, age, BMI, education) |>
    summarize(total_activity = sum(value)) |>
  ggplot(aes(x = age, y = total_activity, color = sex)) + 
   geom_point(alpha = 0.5) +
    geom_smooth(se = FALSE) +
    facet_grid(. ~ education) +
  labs(title = "Male vs. Female: Total Activity and Age Across Education Levels",
       x = "Age (years)",
       y = "Total Activity") 

```

Looking at the plot above, we see some similarities and differences between female and male total activity distribution across age at each education level. 

* At the "High school equivalent" level, females have higher total activity across different ages compared to males. Total activity for female peaked around age 40 then declined with increased age. A small increase is seen around age 70. Males also follow a similar trend, peaking around 40 years then declining to a plateau. 
* At the "Less than high school" level, total activity was higher in females compared to males before 40 years of age. Afterwards, males had higher total activity, peaking at age 60 years old. 
* At the "More than high school" level, females generally have higher total activity compared to males. Both genders experience a general decline in total activity between 50-60 years old. 

#### Task 4


```{r 24-hr activity, echo = FALSE, message = FALSE}
merged_df_updated |>
  mutate(
    min_number = substring(min_number, 4),
    sex = as.factor(sex),
    education = as.factor(education),
    min_number = as.numeric(min_number)) |>
  ggplot(aes(x = min_number, y = value, color = sex)) + 
   geom_point(alpha = 0.03) +
    geom_smooth(se = FALSE) +
    facet_grid(. ~ education) +
  labs(title = "24-Hr Activity Time",
       x = "Time (minute)",
       y = "Total Activity") 
```

Over the course of day, we see that the the 24-hour activity time pattern is similar between those with high school equivalent and less than high school education levels. For those with more than high school education, females have slightly higher total activity levels compared to male. The trend lines for each education level shows similarities between females and males.

## Problem 3

#### Task 1

```{r CitiBike setup, include = FALSE}
Jan2020_df =
  read_csv("./data/CitiBike/Jan 2020 citi.csv", na = c("NA", ".", "")) |>
  tibble(year_month = "Jan2020")

Jan2024_df =
  read_csv("./data/CitiBike/Jan 2024 citi.csv", na = c("NA", ".", "")) |>
  tibble(year_month = "Jan2024")

July2020_df =
  read_csv("./data/CitiBike/July 2020 citi.csv", na = c("NA", ".", "")) |>
  tibble(year_month = "Jul2020")

July2024_df =
  read_csv("./data/CitiBike/July 2024 citi.csv", na = c("NA", ".", "")) |>
  tibble(year_month = "Jul2024")

# data on rides taken on the NYC Citi Bike system. Files contain 1% of all rides with a total duration less than 4 hours in each of four months.
```

4 Citi Bike datasets have been uploaded for this question. All 4 datasets have the same 7 variables. Variable names are already in snake case format. There are 6 character variables = `ride_id`, `rideable_type`, `weekdays`, `start_station_name`, `end_station_name`, and `member_casual`. `Duration` is a numeric variable.

* `Jan2020_df` (`r nrow(Jan2020_df)` rows x `r ncol(Jan2020_df)` columns)
* `July2020_df` (`r nrow(July2020_df)` rows x `r ncol(July2020_df)` columns)
* `Jan2024_df` (`r nrow(Jan2024_df)` rows x `r ncol(Jan2024_df)` columns)
* `July2024_df` (`r nrow(July2024_df)` rows x `r ncol(July2024_df)` columns)

```{r merged bikes, include = FALSE}
merged_bikes = bind_rows(
  Jan2020_df, July2020_df, Jan2024_df, July2024_df) |>
  mutate(
    year_month = as.factor(year_month),
    start_station_name = as.factor(start_station_name),
    end_station_name = as.factor(end_station_name),
    member_casual = as.factor(member_casual),
    weekdays = as.factor(weekdays),
    rideable_type = as.factor(rideable_type))

summary(merged_bikes)

distinct(merged_bikes, start_station_name) #2241 stations
distinct(merged_bikes, end_station_name) #2253 stations
```

Before merging, `year_month` variable is created for each individual dataset. After merging the 4 datasets, the resulting data is stored in `merged_bikes` (`r nrow(merged_bikes)` rows x `r ncol(merged_bikes)` columns). Data for each entry of `ride_id` include:

* `rideable_type` include classic nike or electric bike
* `weekdays` range from Monday to Sunday
* `duration` ranges from 1.002 to 238.78 with a mean of 13.93.
* `start_station_name` contains 2241 distinct names, 43 entries were NAs. 
* `end_station_name` contains 2253 distinct names, 207 entries were NAs.
* `member_casual` include casual and member
* `year_month` variable identifies by Month and the corresponding Year 

#### Task 2

**Total number of rides by Casual riders and Citi Bike members**

```{r, echo = FALSE, message = FALSE}
table = merged_bikes |>
  group_by(year_month, member_casual) |> 
  summarize(total_rides = n()) |>
  pivot_wider(
    names_from = "year_month", 
    values_from = "total_rides") |>
  select(member_casual, Jan2020, Jul2020, Jan2024, Jul2024) |>
  janitor::adorn_totals("row")

knitr::kable(table, col.names = c("Casual rider or Citi Bike member", "Jan 2020", "July 2020", "Jan 2024", "July 2024")) 
```

Citi Bike members make a larger proportion of the total rides for all 4 month-year combination. 
In the month of July for both 2020 and 2024, there is a higher number of rides compared to the month of January in those years. In this table, the highest total number of rides is in July 2024. The lowest number of rides is in January 2020. There are more rides in 2024 than in 2020, January and July rides combined.  


#### Task 3

**Top 5 Most Popular Starting Stations for July 2024**

```{r popular station, echo = FALSE}
popular_stations = merged_bikes |>
  filter(year_month == "Jul2024") |>
  count(start_station_name, sort = TRUE) |>
  slice(1:5)

knitr::kable(popular_stations, col.names = c("Starting Station", "Number of Rides From This Station")) 
```
The table above shows 5 stations that were most popular in July 2024. The number of rides that originated from each of the stations is listed in the table. 

#### Task 4

```{r plot, echo = FALSE, message = FALSE}
dates_df = merged_bikes |>
  mutate(year = substring(year_month, 4),
         month = substring(year_month, 1,3),
         year = as.factor(year),
         month = as.factor(month)) |>
  select(-year_month)

dates_plot = dates_df |> 
  select(ride_id, duration, year, month, weekdays) |>
  group_by(year, month, weekdays) |>
  summarize(med_dur = median(duration)) |>
  mutate(
    weekdays = factor(weekdays, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))) |>
  ggplot(aes(x = weekdays, y = med_dur, fill = month)) +
  geom_bar(stat = "identity", position = "dodge") +
      facet_grid(. ~ year) +
    scale_x_discrete(
    labels = c("Sun", "Mon", "Tues", "Wed", "Thurs", "Fri", "Sat")) + 
    labs(title = "Median ride duration over time",
       x = "Days of the Week",
       y = "Median Ride Duration (min)")
            
dates_plot           
```

In 2020, median ride duration in January was below 10 minutes for all days of the week. Median ride duration in July are higher than in January, with values above 15 minutes for Sunday and Saturday. Weekends have higher median ride duration for both months in 2020 compared to weekdays. 

Median ride duration in January 2024 is lower than in January 2020. The median ride duration is also much lower in July 2024 than in July 2020. Weekends in July 2024 have a higher median ride duration compared to weekdays. For January 2024, there is a slight increase in the median from Tuesday to Saturday.

There is a smaller difference between the two months across all days of the week in 2024. Whereas in 2020, we see a greater difference. 

#### Task 5

```{r setup, echo = FALSE}
plot_setup = dates_df |>
  filter(year == 2024) |>
  mutate(Membership = member_casual, 
         month = case_match(month, 
    "Jan" ~ "January",
    "Jul" ~ "July"),
     rideable_type = case_match(rideable_type, 
    "classic_bike" ~ "Classic Bike",
    "electric_bike" ~ "Electric Bike"),
    Membership = case_match(Membership, 
    "casual" ~ "Casual Rider",
    "member" ~ "Citi Bike Member"))
```

The figure above shows the impact of month, membership status, and bike type on the distribution of ride duration.

```{r}
# month, member_casual, rideable_type, duration
BOX_plot = ggplot(plot_setup, aes(y = duration, x = Membership)) +
  geom_boxplot() +
  facet_grid(rideable_type ~ month) +
      labs(title = "Variables Influencing Ride Duration (2024)",
       x = "Duration (min)")

BOX_plot

box_closeup = 
  ggplot(plot_setup, aes(y = duration, x = Membership)) +
  geom_boxplot() +
      scale_y_continuous(
      limits = c(0, 30),
    breaks = seq(0, 30, by = 2)) +
  facet_grid(rideable_type ~ month) +
      labs(title = "Close-up: Variables Influencing Ride Duration (2024)",
       x = "Duration (min)")

box_closeup
```

Looking at all 4 panels of the figure, we see that the distribution of ride duration is skewed. When stratified by membership status, the bulk of the data falls in the 4 minutes to 20 minutes range for Classic Bikes users and in the 4 minutes to 17 minutes range for Electric Bike users. Looking at the close-up figure, we see that casual riders have a higher mean ride duration than Citi Bike members in all four panels.

Among those who used the classic bike, casual riders have a higher mean duration than Citi Bike members for both January and July. Among those who used the electric bike, this is also true. 

Among casual riders who used the classic bike, mean duration is higher in July than in January. This is also seen for casual riders who used the electric bike. 

Among Citi Bike members who used the classic bike, mean duration is similar between the two months. When electric bike is used, the mean is slightly higher in July. 

In general, mean duration is higher in July, when the classic bike is used, for casual riders.



